{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2559c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2905630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(text):\n",
    "    pc = len(text) # number of paragraphs\n",
    "    wc = sum([len(par.split()) for par in text]) # word count\n",
    "    return pc, wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c385a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_titles(j_dict):\n",
    "    print('Number of chapters:', len(j_dict), '\\n')\n",
    "    for text in j_dict:\n",
    "        print(text['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a35868",
   "metadata": {},
   "source": [
    "## Essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5834f275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 49 \n",
      "\n",
      "Essay 1: Of the Delicacy of Taste and Passion\n",
      "Essay 2: Of the Liberty of the Press\n",
      "Essay 3: That Politics may be Reduced to a Science\n",
      "Essay 4: Of the First Principles of Government\n",
      "Essay 5: Of the Origin of Government\n",
      "Essay 6: Of the Independency of Parliament\n",
      "Essay 7: Whether the British Government inclines more to Absolute Monarchy, or to a Republic\n",
      "Essay 8: Of Parties in General\n",
      "Essay 9: Of the Parties of Great Britain\n",
      "Essay 10: Of Superstition and Enthusiasm\n",
      "Essay 11: Of the Dignity or Meanness of Human Nature\n",
      "Essay 12: Of Civil Liberty\n",
      "Essay 13: Of Eloquence\n",
      "Essay 14: Of the Rise and Progress of the Arts and Sciences\n",
      "Essay 15: The Epicurean\n",
      "Essay 16: The Stoic\n",
      "Essay 17: The Platonist\n",
      "Essay 18: The Sceptic\n",
      "Essay 19: Of Polygamy and Divorces\n",
      "Essay 20: Of Simplicity and Refinement in Writing\n",
      "Essay 21: Of National Characters\n",
      "Essay 22: Of Tragedy\n",
      "Essay 23: Of the Standard of Taste\n",
      "Essay 1: Of Commerce\n",
      "Essay 2: Of Refinement in the Arts\n",
      "Essay 3: Of Money\n",
      "Essay 4: Of Interest\n",
      "Essay 5: Of the Balance of Trade\n",
      "Essay 6: Of the Jealousy of Trade\n",
      "Essay 7: Of the Balance of Power\n",
      "Essay 8: Of Taxes\n",
      "Essay 9: Of Public Credit\n",
      "Essay 10: Of Some Remarkable Customs\n",
      "Essay 11: Of the Populousness of Ancient Nations\n",
      "Essay 12: Of the Original Contract\n",
      "Essay 13: Of Passive Obedience\n",
      "Essay 14: Of the Coalition of Parties\n",
      "Essay 15: Of the Protestant Succession\n",
      "Essay 16: Idea of a Perfect Commonwealth\n",
      "Essay 1: Of Essay Writing\n",
      "Essay 2: Of Moral Prejudices\n",
      "Essay 3: Of the Middle Station of Life\n",
      "Essay 4: Of Impudence and Modesty\n",
      "Essay 5: Of Love and Marriage\n",
      "Essay 6: Of the Study of History\n",
      "Essay 7: Of Avarice\n",
      "Essay 8: A Character of Sir Robert Walpole\n",
      "Essay 1: Of the Immortality of the Soul\n",
      "Essay 2: Of Suicide\n"
     ]
    }
   ],
   "source": [
    "with open('hume_xml/hume.07.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "    \n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "j_dict = []\n",
    "for chapter in chapters[3:]: # first 3 are not essays\n",
    "    \n",
    "    title = chapter.find('head').text\n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find('div', type='section').find_all('p')]\n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'essay',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    j_dict.append(text_dict)\n",
    "    \n",
    "print_titles(j_dict)\n",
    "    \n",
    "with open('hume_json/essays.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acee8728",
   "metadata": {},
   "source": [
    "## History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd37149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(volume, j_dict):\n",
    "    \n",
    "    print(f'hume_xml/hume.1{volume}.xml')\n",
    "    \n",
    "    with open(f'hume_xml/hume.1{volume}.xml', 'r') as file:\n",
    "        file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "    \n",
    "    chapters = file.find_all('div', type='chapter')\n",
    "    \n",
    "    for chapter in chapters:\n",
    "\n",
    "        head = chapter.find('head').text.split('\\n')\n",
    "        number = head[0]\n",
    "\n",
    "        text = [par.text.rstrip('\\n').replace('\\n\\n', ' ') for par in chapter.find_all('p', rend=\"tbindent\") if par.parent['type'] != 'footnote' ]\n",
    "\n",
    "        if not text or number == 'Table of Contents' or number == ' An Historian at Work':\n",
    "            continue\n",
    "            \n",
    "        pc, wc = count(text)\n",
    "\n",
    "        text_dict = {'genre' : 'history',\n",
    "                     'title' : number,\n",
    "                     'word-count': wc,\n",
    "                     'paragraph-count':pc,\n",
    "                     'text' : text}  \n",
    "        j_dict.append(text_dict)\n",
    "        \n",
    "    return j_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a1e2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hume_xml/hume.11.xml\n",
      "hume_xml/hume.12.xml\n",
      "hume_xml/hume.13.xml\n",
      "hume_xml/hume.14.xml\n",
      "hume_xml/hume.15.xml\n",
      "hume_xml/hume.16.xml\n",
      "\n",
      "Number of chapters: 75 \n",
      "\n",
      "I\n",
      "II\n",
      "III\n",
      "APPENDIX I\n",
      "IV\n",
      "V\n",
      "VI\n",
      "VII\n",
      "VIII \n",
      "IX\n",
      "X\n",
      "XI\n",
      "APPENDIX II\n",
      "XII\n",
      "XIII\n",
      "XIV\n",
      "XV\n",
      "XVI\n",
      "XVII\n",
      "XVIII\n",
      "XIX\n",
      "XX\n",
      "XXI\n",
      "XXII\n",
      "XXIII\n",
      "XXIV\n",
      "XXV\n",
      "XXVI\n",
      "XXVII\n",
      "XXVIII\n",
      "XXIX\n",
      "XXX\n",
      "XXXI\n",
      "XXXII\n",
      "XXXIII\n",
      "XXXIV\n",
      "XXXV\n",
      "XXXVI\n",
      "XXXVII\n",
      "XXXVIII\n",
      "XXXIX\n",
      "XL\n",
      "XLI\n",
      "XLII\n",
      "XLIII\n",
      "XLIV\n",
      "APPENDIX III\n",
      "XLV\n",
      "XLVI\n",
      "XLVII\n",
      "XLVIII\n",
      "XLIX\n",
      "APPENDIX TO THE REIGN OF JAMES I{Va(1754), 116: [note]}^*\n",
      "L\n",
      "LI\n",
      "LII\n",
      "LIII\n",
      "LIV\n",
      "LV\n",
      "LVI\n",
      "LVII\n",
      "LVIII \n",
      "LIX\n",
      "LX\n",
      "LXI\n",
      "LXII\n",
      "LXIII\n",
      "LXIV\n",
      "LXV\n",
      "LXVI\n",
      "LXVII\n",
      "LXVIII\n",
      "LXIX\n",
      "LXX\n",
      "LXXI\n"
     ]
    }
   ],
   "source": [
    "j_dict = []\n",
    "for i in range(1, 7):\n",
    "    get_history(i, j_dict)\n",
    "\n",
    "print()\n",
    "print_titles(j_dict)\n",
    "\n",
    "with open('hume_json/history.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d280e5",
   "metadata": {},
   "source": [
    "## Treatise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47347aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 90 \n",
      "\n",
      "SECTION I: OF THE ORIGIN OF OUR IDEAS\n",
      "SECTION II: DIVISION OF THE SUBJECT\n",
      "SECTION III: OF THE IDEAS OF THE MEMORY AND IMAGINATION\n",
      "SECTION IV: OF THE CONNEXION OR ASSOCIATION OF IDEAS\n",
      "SECTION V: OF RELATIONS\n",
      "SECTION VI: OF MODES AND SUBSTANCES\n",
      "SECTION VII: OF ABSTRACT IDEAS\n",
      "SECTION I: OF THE INFINITE DIVISIBILITY OF OUR IDEAS OF SPACE AND TIME\n",
      "SECTION II: OF THE INFINITE DIVISIBILITY OF SPACE AND TIME\n",
      "SECTION III: OF THE OTHER QUALITIES OF OUR IDEAS OF SPACE AND TIME\n",
      "SECTION IV: OBJECTIONS ANSWERED\n",
      "SECTION V: THE SAME SUBJECT CONTINUED\n",
      "SECTION VI: OF THE IDEAS OF EXISTENCE, AND OF EXTERNAL EXISTENCE\n",
      "SECTION I: OF KNOWLEDGE\n",
      "SECTION II: OF PROBABILITY, AND OF THE IDEA OF CAUSE AND EFFECT\n",
      "SECTION III: WHY A CAUSE IS ALWAYS NECESSARY\n",
      "SECTION IV: OF THE COMPONENT PARTS OF OUR REASONINGS CONCERNING CAUSE AND EFFECT\n",
      "SECTION V: OF THE IMPRESSIONS OF THE SENSES AND MEMORY\n",
      "SECTION VI: OF THE INFERENCE FROM THE IMPRESSION TO THE IDEA\n",
      "SECTION VII: OF THE NATURE OF IDEA OR BELIEF\n",
      "SECTION VIII: OF THE CAUSES OF BELIEF\n",
      "SECTION IX: OF THE EFFECTS OF OTHER RELATIONS AND OTHER HABITS\n",
      "SECTION X: OF THE INFLUENCE OF BELIEF\n",
      "SECTION XI: OF THE PROBABILITY OF CHANCES\n",
      "SECTION XII: OF THE PROBABILITY OF CAUSES\n",
      "SECTION XIII: OF UNPHILOSOPHICAL PROBABILITY\n",
      "SECTION XIV: OF THE IDEA OF NECESSARY CONNEXION\n",
      "SECTION XV: RULES BY WHICH TO JUDGE OF CAUSES AND EFFECTS\n",
      "SECTION XVI: OF THE REASON OF ANIMALS\n",
      "SECTION I: OF SCEPTICISM WITH REGARD TO REASON\n",
      "SECTION II: OF SCEPTICISM WITH REGARD TO THE SENSES\n",
      "SECTION III: OF THE ANCIENT PHILOSOPHY\n",
      "SECTION IV: OF THE MODERN PHILOSOPHY\n",
      "SECTION V: OF THE IMMATERIALITY OF THE SOUL\n",
      "SECTION VI: OF PERSONAL IDENTITY\n",
      "SECTION VII: CONCLUSION OF THIS BOOK\n",
      "SECTION I: DIVISION OF THE SUBJECT\n",
      "SECTION II: OF PRIDE AND HUMILITY; THEIR OBJECTS AND CAUSES\n",
      "SECTION III: WHENCE THESE OBJECTS AND CAUSES ARE DERIVED\n",
      "SECTION IV: OF THE RELATIONS OF IMPRESSIONS AND IDEAS\n",
      "SECTION V: OF THE INFLUENCE OF THESE RELATIONS ON PRIDE AND HUMILITY\n",
      "SECTION VI: LIMITATIONS OF THIS SYSTEM\n",
      "SECTION VII: OF VICE AND VIRTUE\n",
      "SECTION VIII: OF BEAUTY AND DEFORMITY\n",
      "SECTION IX: OF EXTERNAL ADVANTAGES AND DISADVANTAGES\n",
      "SECTION X: OF PROPERTY AND RICHES\n",
      "SECTION XI: OF THE LOVE OF FAME\n",
      "SECTION XII: OF THE PRIDE AND HUMILITY OF ANIMALS\n",
      "SECTION I: OF THE OBJECT AND CAUSES OF LOVE AND HATRED\n",
      "SECTION II: EXPERIMENTS TO CONFIRM THIS SYSTEM\n",
      "SECTION III: DIFFICULTIES SOLVED\n",
      "SECTION IV: OF THE LOVE OF RELATIONS\n",
      "SECTION V: OF OUR ESTEEM FOR THE RICH AND POWERFUL\n",
      "SECTION VI: OF BENEVOLENCE AND ANGER\n",
      "SECTION VII: OF COMPASSION\n",
      "SECTION VIII: OF MALICE AND ENVY\n",
      "SECTION IX: OF THE MIXTURE OF BENEVOLENCE AND ANGER WITH COMPASSION AND MALICE\n",
      "SECTION X: OF RESPECT AND CONTEMPT\n",
      "SECTION XI: OF THE AMOROUS PASSION, OR LOVE BETWIXT THE SEXES\n",
      "SECTION XII: OF THE LOVE AND HATRED OF ANIMALS\n",
      "SECTION I: OF LIBERTY AND NECESSITY\n",
      "SECTION II: THE SAME SUBJECT CONTINUED\n",
      "SECTION III: OF THE INFLUENCING MOTIVE OF THE WILL\n",
      "SECTION IV: OF THE CAUSES OF THE VIOLENT PASSIONS\n",
      "SECTION V: OF THE EFFECTS OF CUSTOM\n",
      "SECTION VI: OF THE INFLUENCE OF THE IMAGINATION ON THE PASSIONS\n",
      "SECTION VII: OF CONTIGUITY AND DISTANCE IN SPACE AND TIME\n",
      "SECTION VIII: THE SAME SUBJECT CONTINUED\n",
      "SECTION IX: OF THE DIRECT PASSIONS\n",
      "SECTION X: OF CURIOSITY OR THE LOVE OF TRUTH\n",
      "SECTION I: MORAL DISTINCTIONS NOT DERIVED FROM REASON\n",
      "SECTION II: MORAL DISTINCTIONS DERIVED FROM A MORAL SENSE\n",
      "SECTION I: JUSTICE, WHETHER A NATURAL OR ARTIFICIAL VIRTUE?\n",
      "SECTION II: OF THE ORIGIN OF JUSTICE AND PROPERTY\n",
      "SECTION III: OF THE RULES WHICH DETERMINE PROPERTY\n",
      "SECTION IV: OF THE TRANSFERENCE OF PROPERTY BY CONSENT\n",
      "SECTION V: OF THE OBLIGATION OF PROMISES\n",
      "SECTION VI: SOME FURTHER REFLECTIONS CONCERNING JUSTICE AND INJUSTICE\n",
      "SECTION VII: OF THE ORIGIN OF GOVERNMENT\n",
      "SECTION VIII: OF THE SOURCE OF ALLEGIANCE\n",
      "SECTION IX: OF THE MEASURES OF ALLEGIANCE\n",
      "SECTION X: OF THE OBJECTS OF ALLEGIANCE\n",
      "SECTION XI: OF THE LAWS OF NATIONS\n",
      "SECTION XII: OF CHASTITY AND MODESTY\n",
      "SECTION I: OF THE ORIGIN OF THE NATURAL VIRTUES AND VICES\n",
      "SECTION II: OF GREATNESS OF MIND\n",
      "SECTION III: OF GOODNESS AND BENEVOLENCE\n",
      "SECTION IV: OF NATURAL ABILITIES\n",
      "SECTION V: SOME FURTHER REFLECTIONS CONCERNING THE NATURAL VIRTUES\n",
      "SECTION VI: CONCLUSION OF THIS BOOK\n"
     ]
    }
   ],
   "source": [
    "with open('hume_xml/hume.02.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "    \n",
    "# missing Introduction and chapter/book division\n",
    "sections = file.find_all('div', type='section')\n",
    "\n",
    "j_dict = []\n",
    "for section in sections: \n",
    "    \n",
    "    title = section.find('head').text\n",
    "    \n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in section.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'treatise',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    \n",
    "    j_dict.append(text_dict)\n",
    "    \n",
    "print_titles(j_dict)\n",
    "\n",
    "with open('hume_json/treatise.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdaa60b",
   "metadata": {},
   "source": [
    "## Enquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7998ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hume_xml/hume.05.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "j_dict = []\n",
    "\n",
    "# ignore table of contents, publishing info, author's advertisment, footnotes, variants\n",
    "for chapter in chapters[3:-2]: \n",
    "    \n",
    "    title = chapter.find('head').text\n",
    "    \n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'enquiry HU',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    \n",
    "    j_dict.append(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8fa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hume_xml/hume.06.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "    \n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "# ignore table of contents, publishing info, author's advertisment, footnotes, variants, list of editions\n",
    "for chapter in chapters[2:-3]: \n",
    "    \n",
    "    title = chapter.find('head').text\n",
    "    \n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'enquiry PoM',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    j_dict.append(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631491f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 26 \n",
      "\n",
      "Section 1: Of the Different Species of Philosophy\n",
      "Section 2: Of the Origin of Ideas\n",
      "Section 3: Of the Association of Ideas\n",
      "Section 4: Sceptical Doubts concerning the Operations of the Understanding\n",
      "Section 5: Sceptical Solution of these Doubts\n",
      "Section 6: Of Probability\n",
      "Section 7: Of the Idea of Necessary Connexion\n",
      "Section 8: Of Liberty and Necessity\n",
      "Section 9: Of the Reason of Animals\n",
      "Section 10: Of Miracles\n",
      "Section 11: Of a Particular Providence and of a Future State\n",
      "Section 12: Of the Academical or Sceptical Philosophy\n",
      "Section 1: Of the General Principles of Morals\n",
      "Section 2 : Of Benevolence\n",
      "Section 3: Of Justice\n",
      "Section 4: Of Political Society\n",
      "Section 5: Why Utility Pleases\n",
      "Section 6: Of Qualities useful to Ourselves\n",
      "Section 7: Of Qualities immediately Agreeable to Ourselves\n",
      "Section 8: Of Qualities immediately Agreeable to Others\n",
      "Section 9: Conclusion\n",
      "Appendix 1: Concerning Moral Sentiment\n",
      "Appendix 2: Of Self-Love\n",
      "Appendix 3: Some Farther Considerations with regard to Justice\n",
      "Appendix 4: Of Some Verbal Disputes\n",
      "A Dialogue\n"
     ]
    }
   ],
   "source": [
    "print_titles(j_dict)\n",
    "with open('hume_json/enquiries.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ab4f2",
   "metadata": {},
   "source": [
    "## A Dissertation of The Passions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "896f97ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 6 \n",
      "\n",
      "Section 1\n",
      "Section 2\n",
      "Section 3\n",
      "Section 4\n",
      "Section 5\n",
      "Section 6\n"
     ]
    }
   ],
   "source": [
    "with open('hume_xml/hume.08.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "j_dict = []\n",
    "\n",
    "# ignore table of contents, publishing info, footnotes, variants\n",
    "for chapter in chapters[2:-2]: \n",
    "    title = chapter.find('head').text\n",
    "\n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'dissertation',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    \n",
    "    j_dict.append(text_dict)\n",
    "    \n",
    "print_titles(j_dict)\n",
    "with open('hume_json/dissertation.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee9df75",
   "metadata": {},
   "source": [
    "## Natural History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2817ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 16 \n",
      "\n",
      "Introduction\n",
      "Section 1: That Polytheism was the Primary Religion of Man\n",
      "Section 2: Origin of Polytheism\n",
      "Section 3: The Same Subject Continued\n",
      "Section 4: Deities not considered as Creators or Formers of the World\n",
      "Section 5: Various Forms of Polytheism: Allegory, Hero-Worship\n",
      "Section 6: Origin of Theism from Polytheism\n",
      "Section 7: Confirmation of this Doctrine\n",
      "Section 8: Flux and Reflux of Polytheism and Theism\n",
      "Section 9: Comparison of these Religions, with regard to Persecution and Toleration\n",
      "Section 10: With regard to Courage or Abasement\n",
      "Section 11: With regard to Reason or Absurdity\n",
      "Section 12: With regard to Doubt or Conviction\n",
      "Section 13: Impious Conceptions of the Divine Nature in Popular Religions of both Kinds\n",
      "Section 14: Bad Influence of Popular Religions on Morality\n",
      "Section 15: General Corollary\n"
     ]
    }
   ],
   "source": [
    "with open('hume_xml/hume.09.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "j_dict = []\n",
    "\n",
    "# ignore table of contents, publishing info, footnotes, variants\n",
    "for chapter in chapters[2:-2]: \n",
    "    title = chapter.find('head').text\n",
    "\n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'natural history',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    \n",
    "    j_dict.append(text_dict)\n",
    "    \n",
    "print_titles(j_dict)\n",
    "\n",
    "with open('hume_json/natural history.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3085e05d",
   "metadata": {},
   "source": [
    "## Dialogues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ec1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 13 \n",
      "\n",
      "Pamphilus to Hermippus\n",
      "Part 1\n",
      "Part 2\n",
      "Part 3\n",
      "Part 4\n",
      "Part 5\n",
      "Part 6\n",
      "Part 7\n",
      "Part 8\n",
      "Part 9\n",
      "Part 10\n",
      "Part 11\n",
      "Part 12\n"
     ]
    }
   ],
   "source": [
    "with open('hume_xml/hume.10.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "chapters = file.find_all('div', type='chapter')\n",
    "\n",
    "j_dict = []\n",
    "\n",
    "# ignore table of contents, publishing info, footnotes, variants\n",
    "for chapter in chapters[2:-1]: \n",
    "    title = chapter.find('head').text\n",
    "\n",
    "    text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in chapter.find_all('p')]\n",
    "    \n",
    "    pc, wc = count(text)\n",
    "    \n",
    "    text_dict = {'genre' : 'dialogues',\n",
    "                 'title' : title,\n",
    "                 'word-count': wc,\n",
    "                 'paragraph-count':pc,\n",
    "                 'text' : text}  \n",
    "    \n",
    "    j_dict.append(text_dict)\n",
    "    \n",
    "print_titles(j_dict)\n",
    "    \n",
    "with open('hume_json/dialogues.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6fef8",
   "metadata": {},
   "source": [
    "## An Abstract of A Treatise of Human Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c82f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hume_xml/hume.03.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "books = file.find_all('div', type='book')\n",
    "\n",
    "paragraphs = []\n",
    "\n",
    "paragraphs.append(books[0].find_all('p', rend='center')[-1])\n",
    "paragraphs.extend(books[0].find_all('p', rend='tbindent'))\n",
    "\n",
    "paragraphs.append(books[1].find_all('p', rend='center')[-2]) # missing FINIS. now\n",
    "paragraphs.extend(books[1].find_all('p', rend='tbindent'))\n",
    "\n",
    "j_dict = []\n",
    "title = 'An Abstract of A Treatise of Human Nature'\n",
    "\n",
    "text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in paragraphs]\n",
    "\n",
    "pc, wc = count(text)\n",
    "\n",
    "text_dict = {'genre' : 'abstract',\n",
    "             'title' : title,\n",
    "             'word-count': wc,\n",
    "             'paragraph-count':pc,\n",
    "             'text' : text}  \n",
    "j_dict.append(text_dict)\n",
    "\n",
    "with open('hume_json/abstract.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10a27e",
   "metadata": {},
   "source": [
    "## A letter from a Gentleman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be6288eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hume_xml/hume.04.xml', 'r') as file:\n",
    "    file = bs.BeautifulSoup(file.read(), \"xml\")\n",
    "\n",
    "books = file.find_all('div', type='book')\n",
    "\n",
    "j_dict = []\n",
    "\n",
    "title = 'A Letter from a Gentleman'\n",
    "\n",
    "text = [par.text.rstrip('\\n').replace('\\n', ' ') for par in books[1].find_all('p')]\n",
    "\n",
    "pc, wc = count(text)\n",
    "\n",
    "text_dict = {'genre' : 'letter',\n",
    "             'title' : title,\n",
    "             'word-count': wc,\n",
    "             'paragraph-count':pc,\n",
    "             'text' : text}  \n",
    "j_dict.append(text_dict)\n",
    "\n",
    "with open('hume_json/letter.json', 'w') as file:\n",
    "    json.dump(j_dict, file, indent=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1236117d",
   "metadata": {},
   "source": [
    "## Merge all files into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86383ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jq -s 'add' hume_json/* > all_raw.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9dbe9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98b055bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('all_raw.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb782845",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a99155cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
